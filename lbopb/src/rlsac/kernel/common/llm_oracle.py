# SPDX-License-Identifier: GPL-3.0-only
# Copyright (C) 2025 GaoZheng
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, version 3 only.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
#
# --- è‘—ä½œæƒç‹¬ç«‹æ€§å£°æ˜ (Copyright Independence Declaration) ---
# æœ¬æ–‡ä»¶ï¼ˆâ€œè½½è·â€ï¼‰æ˜¯ä½œè€… (GaoZheng) çš„åŸåˆ›è‘—ä½œç‰©ï¼Œå…¶çŸ¥è¯†äº§æƒ
# ç‹¬ç«‹äºå…¶è¿è¡Œå¹³å° GROMACSï¼ˆâ€œå®¿ä¸»â€ï¼‰ã€‚
# æœ¬æ–‡ä»¶çš„æˆæƒéµå¾ªä¸Šè¿° SPDX æ ‡è¯†ï¼Œä¸å—â€œå®¿ä¸»â€è®¸å¯è¯çš„ç®¡è¾–ã€‚
# è¯¦æƒ…å‚è§é¡¹ç›®æ–‡æ¡£ "my_docs/project_docs/1762636780_ğŸš©ğŸš©gromacs-2024.1_developeré¡¹ç›®çš„è‘—ä½œæƒè®¾è®¡ç­–ç•¥ï¼šâ€œå®¿ä¸»-è½½è·â€ä¸â€œåŒè½¨åˆ¶â€å¤åˆæ¶æ„.md"ã€‚
# ------------------------------------------------------------------

from __future__ import annotations

from typing import Optional, Any, Dict, List
from pathlib import Path
import os
import time as _t
import json


def call_llm(prompt: str, *, provider: str = "gemini", model: str | None = None, api_key: str | None = None) -> Optional[str]:
    """è½»é‡çš„ LLM è°ƒç”¨å°è£…ï¼ˆé»˜è®¤ä½¿ç”¨å¤–éƒ¨ my_scripts.gemini_clientï¼‰ã€‚

    - è¿”å›å€¼ä¸ºå­—ç¬¦ä¸²æ—¶è¡¨ç¤ºæˆåŠŸï¼›è¿”å› None è¡¨ç¤ºå¤±è´¥æˆ–æœªè°ƒç”¨æˆåŠŸã€‚
    - å…·ä½“ HTTP é€»è¾‘åœ¨å¤–éƒ¨å®¢æˆ·ç«¯ä¸­å®ç°ï¼Œè¿™é‡Œä»…åšåŠ¨æ€å¯¼å…¥ä¸å®¹é”™ã€‚
    """
    try:
        dbg = bool(os.environ.get("LBOPB_GEMINI_DEBUG") or os.environ.get("GEMINI_DEBUG"))
        if provider.lower() == "gemini":
            import importlib
            if dbg:
                print(f"[LLM] call_llm enter: provider=gemini, t={int(_t.time())}")
            cli = importlib.import_module("my_scripts.gemini_client")
            try:
                if model:
                    os.environ["LBOPB_GEMINI_MODEL"] = str(model)
                    os.environ.setdefault("GEMINI_MODEL", str(model))
            except Exception:
                pass
            for fname in ("ask", "generate", "chat", "gemini_text", "query", "run", "generate_gemini_content"):
                fn = getattr(cli, fname, None)
                if callable(fn):
                    if dbg:
                        print(f"[LLM] call_llm try func={fname}")
                    try:
                        try:
                            res: Any = fn(prompt, model=model)  # type: ignore[call-arg]
                        except TypeError:
                            res = fn(prompt)
                        if isinstance(res, str):
                            if dbg:
                                _h = res[:120] + ("..." if len(res) > 120 else "")
                                print(f"[LLM] call_llm ok via {fname}, len={len(res)}, head={_h}")
                            return res
                        if hasattr(res, "text"):
                            s = str(getattr(res, "text"))
                            if dbg:
                                _h = s[:120] + ("..." if len(s) > 120 else "")
                                print(f"[LLM] call_llm ok via {fname}.text, len={len(s)}, head={_h}")
                            return s
                    except Exception as e:
                        if dbg:
                            print(f"[LLM] call_llm func={fname} exception: {e}")
                        continue
    except Exception as e:
        if bool(os.environ.get("LBOPB_GEMINI_DEBUG") or os.environ.get("GEMINI_DEBUG")):
            print(f"[LLM] call_llm outer exception: {e}")
        pass
    return None


# ---- å…¬ç†æ–‡æ¡£è·¯å¾„æ˜ å°„ï¼ˆé»˜è®¤å…œåº•ï¼›ä¼˜å…ˆç”¨åŒç›®å½• JSON è¦†ç›–ï¼‰ ----

DOC_MAP: Dict[str, str] = {
    "pem": "my_docs/project_docs/1761062400_ç—…ç†æ¼”åŒ–å¹ºåŠç¾¤ (PEM) å…¬ç†ç³»ç»Ÿ.md",
    "prm": "my_docs/project_docs/1761062401_ç”Ÿç†è°ƒæ§å¹ºåŠç¾¤ (PRM) å…¬ç†ç³»ç»Ÿ.md",
    "tem": "my_docs/project_docs/1761062402_æ¯’ç†å­¦æ•ˆåº”å¹ºåŠç¾¤ (TEM) å…¬ç†ç³»ç»Ÿ.md",
    "pktm": "my_docs/project_docs/1761062403_è¯ä»£è½¬è¿å¹ºåŠç¾¤ (PKTM) å…¬ç†ç³»ç»Ÿ.md",
    "pgom": "my_docs/project_docs/1761062404_è¯ç†åŸºå› ç»„å¹ºåŠç¾¤ (PGOM) å…¬ç†ç³»ç»Ÿ.md",
    "pdem": "my_docs/project_docs/1761062405_è¯æ•ˆæ•ˆåº”å¹ºåŠç¾¤ (PDEM) å…¬ç†ç³»ç»Ÿ.md",
    "iem": "my_docs/project_docs/1761062406_å…ç–«æ•ˆåº”å¹ºåŠç¾¤ (IEM) å…¬ç†ç³»ç»Ÿ.md",
}


# åœ¨è”ç»œä¸€è‡´æ€§ä¸­ä½¿ç”¨çš„â€œå¯¹å¶åŸŸâ€æ£€æŸ¥å¯¹
PAIRWISE: List[tuple[str, str]] = [
    ("pdem", "pktm"),
    ("pgom", "pem"),
    ("tem", "pktm"),
    ("prm", "pem"),
    ("iem", "pem"),
]


def _load_doc_map() -> Dict[str, str]:
    """ä»åŒç›®å½• axiom_docs.json åŠ è½½è¦†ç›–æ˜ å°„ï¼›é”®ç»Ÿä¸€å°å†™ã€‚"""
    m = dict(DOC_MAP)
    try:
        here = Path(__file__).resolve().parent
        cfg = here / "axiom_docs.json"
        if cfg.exists():
            data = json.loads(cfg.read_text(encoding="utf-8"))
            if isinstance(data, dict):
                for k, v in data.items():
                    try:
                        m[str(k).strip().lower()] = str(v)
                    except Exception:
                        continue
    except Exception:
        pass
    return m


def build_pathfinder_prompt(domain: str, sequence: List[str],
                            ops_detailed: Optional[List[Dict[str, Any]]] = None,
                            extra: Optional[Dict[str, Any]] = None) -> str:
    d = (domain or "").lower()
    doc_rel = _load_doc_map().get(d, "<axiom-doc-not-found>")
    # è¯»å–å…¬ç†æ–‡æ¡£
    doc_text = "<axiom-doc-content-not-found>"
    try:
        repo_root = Path(__file__).resolve().parents[5]
        doc_path = repo_root / doc_rel
        if doc_path.exists():
            doc_text = doc_path.read_text(encoding="utf-8")
        else:
            raise FileNotFoundError(f"Axiom document not found for domain '{d}': {doc_path}")
    except Exception:
        raise

    # å¯é€‰ï¼šé™„å¸¦å‚æ•°/ç½‘æ ¼ç´¢å¼•ä¾› LLM å‚è€ƒ
    param_block = ""
    if isinstance(ops_detailed, list) and len(ops_detailed) > 0:
        try:
            import json as _json
            simplified: List[Dict[str, Any]] = []
            for st in ops_detailed:
                row: Dict[str, Any] = {"name": st.get("name"), "params": st.get("params")}
                if st.get("grid_index") is not None:
                    row["grid_index"] = st.get("grid_index")
                simplified.append(row)
            meta: Dict[str, Any] = {}
            if isinstance(extra, dict):
                for k in ("op_space_id", "op_space_ref"):
                    if k in extra:
                        meta[k] = extra[k]
            param_block = (
                "\nï¼ˆä»¥ä¸‹ä¸ºå¯é€‰è¡¥å……ï¼‰:\n"
                + (f"meta={_json.dumps(meta, ensure_ascii=False)}\n" if meta else "")
                + f"steps={_json.dumps(simplified, ensure_ascii=False)}\n"
            )
        except Exception:
            param_block = ""

    return (
        "ä½ æ˜¯ä¸€åä¸¥æ ¼çš„å½¢å¼ç³»ç»Ÿå®¡æŸ¥å™¨ã€‚\n"
        f"å¹ºåŠç¾¤åŸŸ: {d}\n"
        "ä»¥ä¸‹æ˜¯è¯¥åŸŸçš„å…¬ç†æ–‡æ¡£ï¼š\n"
        "-----BEGIN AXIOM DOC-----\n"
        f"{doc_text}\n"
        "-----END AXIOM DOC-----\n"
        "ä»»åŠ¡: ä¸¥æ ¼ä¾æ®ä»¥ä¸Šå…¬ç†æ–‡æ¡£å†…å®¹, åˆ¤æ–­ä»¥ä¸‹åŸºæœ¬ç®—å­åºåˆ—(ç®—å­åŒ…)æ˜¯å¦ä¸¥æ ¼ç¬¦åˆè¯¥åŸŸçš„å…¬ç†ç³»ç»Ÿ(æ‰€æœ‰å¿…è¦çº¦æŸ: æ–¹å‘æ€§/ä¸å¯äº¤æ¢/åºæ¬¡/é˜ˆå€¼/åœæœºç­‰)ã€‚\n"
        f"ç®—å­åºåˆ—: {sequence}\n"
        f"{param_block}"
        "è¦æ±‚: ä»…è¿”å›å­—ç¬¦ '1' æˆ– '0'ã€‚1 è¡¨ç¤ºç¬¦åˆå…¬ç†ç³»ç»Ÿ, 0 è¡¨ç¤ºä¸ç¬¦åˆã€‚\n"
    )


def build_connector_prompt(conn: Dict[str, List[str]]) -> str:
    """è”ç»œä¸€è‡´æ€§æ£€éªŒæç¤ºè¯ï¼šè·¨åŸŸå¯¹å¶æ£€æŸ¥ã€‚"""
    parts = []
    doc_map = _load_doc_map()
    for a, b in PAIRWISE:
        da = doc_map.get(a, "<doc-na>")
        db = doc_map.get(b, "<doc-na>")
        sa = conn.get(a, [])
        sb = conn.get(b, [])
        parts.append({
            "pair": f"{a}<->{b}",
            "doc_a": da,
            "doc_b": db,
            "seq_a": sa,
            "seq_b": sb,
        })
    header = (
        "ä½ æ˜¯ä¸€åä¸¥æ ¼çš„å½¢å¼ç³»ç»Ÿå®¡æŸ¥å™¨ï¼Œéœ€åˆ¤æ–­è·¨åŸŸå¯¹å¶çš„è¿é€šæ€§/ä¸€è‡´æ€§ã€‚\n"
        "è¯·åœ¨å„è‡ªå…¬ç†ç³»ç»Ÿä¸‹ï¼Œå¯¹ä¸‹åˆ—å¯¹å¶åŸŸåºåˆ—é€ä¸€æ£€æŸ¥ï¼ˆæ–¹å‘/æ¬¡åº/æ—¶åº/é˜ˆå€¼ï¼‰ã€‚\n"
    )
    body = "\n".join([
        (
            f"å¯¹å¶å¯¹ {p['pair']}\n"
            f"æ–‡æ¡£A: {p['doc_a']}\næ–‡æ¡£B: {p['doc_b']}\n"
            f"åºåˆ—A: {p['seq_a']}\nåºåˆ—B: {p['seq_b']}\n"
        ) for p in parts
    ])
    tail = (
        "ä¸¥æ ¼åˆ¤æ–­å¯¹å¶å¯¹æ˜¯å¦ä¸€è‡´ï¼šè‹¥æ‰€æœ‰å¯¹å¶å¯¹å‡ä¸è¿åä»»ä½•å…¬ç†ï¼Œè¿”å› '1'ï¼›å¦åˆ™è¿”å› '0'ã€‚\n"
        "ä»…è¿”å›å­—ç¬¦ '1' æˆ– '0'ã€‚\n"
    )
    return header + body + "\n" + tail
