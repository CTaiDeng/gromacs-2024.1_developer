# SPDX-License-Identifier: GPL-3.0-only
# Copyright (C) 2025 GaoZheng
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, version 3 only.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
#
# --- è‘—ä½œæƒç‹¬ç«‹æ€§å£°æ˜ (Copyright Independence Declaration) ---
# æœ¬æ–‡ä»¶ï¼ˆâ€œè½½è·â€ï¼‰æ˜¯ä½œè€… (GaoZheng) çš„åŸåˆ›è‘—ä½œç‰©ï¼Œå…¶çŸ¥è¯†äº§æƒ
# ç‹¬ç«‹äºå…¶è¿è¡Œå¹³å° GROMACSï¼ˆâ€œå®¿ä¸»â€ï¼‰ã€‚
# æœ¬æ–‡ä»¶çš„æˆæƒéµå¾ªä¸Šè¿° SPDX æ ‡è¯†ï¼Œä¸å—â€œå®¿ä¸»â€è®¸å¯è¯çš„ç®¡è¾–ã€‚
# è¯¦æƒ…å‚è§é¡¹ç›®æ–‡æ¡£ "my_docs/project_docs/1762636780_ğŸš©ğŸš©gromacs-2024.1_developeré¡¹ç›®çš„è‘—ä½œæƒè®¾è®¡ç­–ç•¥ï¼šâ€œå®¿ä¸»-è½½è·â€ä¸â€œåŒè½¨åˆ¶â€å¤åˆæ¶æ„.md"ã€‚
# ------------------------------------------------------------------

from __future__ import annotations

import json
import time as _pytime
from pathlib import Path
from typing import Any, Dict, List, Tuple

try:
    from .domain import get_domain_spec  # type: ignore
except Exception:
    # ç›´æ¥è„šæœ¬è¿è¡Œçš„å…œåº•å¯¼å…¥
    from pathlib import Path as _Path
    import sys as _sys
    _sys.path.insert(0, str(_Path(__file__).resolve().parents[5]))
    from lbopb.src.rlsac.kernel.rlsac_pathfinder.domain import get_domain_spec  # type: ignore


def _store_dir() -> Path:
    """è¿”å›ç”¨äºå­˜æ”¾å„å¹ºåŠç¾¤ç®—å­åŒ…çš„ç›®å½•è·¯å¾„ã€‚"""
    return Path(__file__).resolve().parent / "monoid_packages"


def ensure_store_dir() -> Path:
    p = _store_dir()
    p.mkdir(parents=True, exist_ok=True)
    return p


def _store_file_for_domain(domain: str) -> Path:
    spec = get_domain_spec(domain)
    # å¤ç”¨è§„èŒƒåŒ–æ–‡ä»¶åï¼Œä½†å½’æ¡£äºä¸“ç”¨ç›®å½•ä¸‹
    return ensure_store_dir() / spec.dict_filename


def _compute_score(delta_risk: float, cost: float, cost_lambda: float) -> float:
    try:
        return float(delta_risk) - float(cost_lambda) * float(cost)
    except Exception:
        return float(delta_risk)


def _normalize_lf(text: str) -> str:
    # ç»Ÿä¸€ä¸º LF è¡Œå°¾
    return text.replace("\r\n", "\n")


def ingest_from_debug_dataset(debug_dataset_path: str | Path, *, domain: str | None = None,
                              cost_lambda: float = 0.2) -> Path:
    """
    ä» debug_dataset.json ä¸­æå– label=1 çš„â€œæ­£ç¡®â€ç®—å­åŒ…ï¼ŒæŒ‰åºåˆ—å»é‡çº³å…¥ï¼Œå¹¶æŒ‰ score é‡æ–°æ’åºåè½ç›˜ã€‚

    - æ’åºè§„åˆ™ï¼šscore(desc) -> length(asc) -> sequence(å­—å…¸åº)
    - score = delta_risk - cost_lambda * cost

    è¿”å›ï¼šè¯¥å¹ºåŠç¾¤å¯¹åº”çš„æ±‡æ€» JSON æ–‡ä»¶è·¯å¾„ã€‚
    """
    debug_dataset_path = Path(debug_dataset_path)
    if not debug_dataset_path.exists():
        raise FileNotFoundError(f"debug dataset not found: {debug_dataset_path}")

    data = json.loads(debug_dataset_path.read_text(encoding="utf-8"))
    ds_domain = str((domain or data.get("domain") or "")).strip().lower()
    if not ds_domain:
        raise ValueError("domain is required (either from file or argument)")

    samples: List[Dict[str, Any]] = list(data.get("samples", []) or [])
    out_path = _store_file_for_domain(ds_domain)

    # è¯»å–ç°æœ‰èšåˆ
    existing: List[Dict[str, Any]] = []
    if out_path.exists():
        try:
            existing = json.loads(out_path.read_text(encoding="utf-8"))
        except Exception:
            existing = []

    # åŸºäº sequence å»é‡çš„ map
    def _seq_key(seq: List[str]) -> Tuple[str, ...]:
        return tuple(str(x) for x in (seq or []))

    by_seq: Dict[Tuple[str, ...], Dict[str, Any]] = {}
    for item in existing:
        seq = list(item.get("sequence", []) or [])
        by_seq[_seq_key(seq)] = item

    # çº³å…¥æ–°æ ·æœ¬ï¼ˆä»… label==1ï¼‰
    ts_now = int(_pytime.time())
    for it in samples:
        try:
            if int(it.get("label", 0)) != 1:
                continue
            seq = list(it.get("sequence", []) or [])
            feats = it.get("features", {}) if isinstance(it.get("features", {}), dict) else {}
            judge = it.get("judge", {}) if isinstance(it.get("judge", {}), dict) else {}
            # ä¸¤å¤„æ‹©ä¼˜å–æ•°
            dr = float(feats.get("delta_risk", judge.get("delta_risk", 0.0)))
            cost = float(feats.get("cost", judge.get("cost", 0.0)))
            length = int(feats.get("length", len(seq)))
            score = _compute_score(dr, cost, cost_lambda)

            # é€ä¼ å¯é€‰çš„â€œç»†åŒ–ç®—å­/ç©ºé—´â€å­—æ®µï¼ˆè‹¥å­˜åœ¨ï¼‰ï¼Œä»¥å¢å¼ºå¯å¤ç°æ€§
            _ext_keys = (
                "op_space_id",
                "op_space_ref",
                "ops_detailed",
                "op_index_seq",
                # æ³¨æ„ï¼šä¸è¦æäº¤æ•°å€¼åºåˆ—ï¼Œæ•…ä¸é€ä¼  op_param_seq
                # "op_param_seq",
                "env_state",
                "trace",
            )
            ext: Dict[str, Any] = {}
            for k in _ext_keys:
                if k in it and it.get(k) is not None:
                    ext[k] = it.get(k)

            # è‹¥æä¾›äº† ops_detailed + op_space_refï¼Œåˆ™ä¾æ®ç©ºé—´åæŸ¥å¹¶è§„èŒƒåŒ– params
            try:
                if isinstance(ext.get("ops_detailed"), list) and ext.get("op_space_ref"):
                    from .op_space_utils import load_op_space, normalize_ops_detailed  # type: ignore
                    space = load_op_space(str(ext["op_space_ref"]))
                    norm_steps, warns, errs = normalize_ops_detailed(ext["ops_detailed"], space)
                    if errs:
                        # è§„èŒƒå¤±è´¥ä¸ç»ˆæ­¢ï¼Œä»…è®°å½•åœ¨æ‰©å±•çš„ warnings ä¸­
                        ext.setdefault("syntax_warnings", [])
                        ext["syntax_warnings"].extend([f"ops_detailed: {m}" for m in errs])
                    else:
                        ext["ops_detailed"] = norm_steps
                    if warns:
                        ext.setdefault("syntax_warnings", [])
                        ext["syntax_warnings"].extend([f"ops_detailed: {m}" for m in warns])
                # è‹¥æ ·æœ¬æœªæä¾› ops_detailedï¼Œåˆ™æŒ‰åŸŸé»˜è®¤ç©ºé—´ï¼ˆv1ï¼‰ç”Ÿæˆâ€œä¸­ä½å€¼â€å‚æ•°å¹¶è¡¥å…¨
                if not ext.get("ops_detailed"):
                    try:
                        from .op_space_utils import load_op_space, param_grid_of, params_from_grid  # type: ignore
                        mod_dir = Path(__file__).resolve().parent
                        space_ref = mod_dir / "operator_spaces" / f"{ds_domain}_op_space.v1.json"
                        if space_ref.exists():
                            space = load_op_space(str(space_ref))
                            steps = []
                            for nm in seq:
                                try:
                                    names, grids = param_grid_of(space, nm)
                                except Exception:
                                    steps.append({"name": nm})
                                    continue
                                gi = []
                                for g in grids:
                                    L = len(g)
                                    gi.append(max(0, (L - 1) // 2))
                                prs = params_from_grid(space, nm, gi)
                                steps.append({"name": nm, "grid_index": gi, "params": prs})
                            if steps:
                                ext["ops_detailed"] = steps
                                ext["op_space_id"] = space.get("space_id", f"{ds_domain}.v1")
                                # ç»Ÿä¸€ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºä»“åº“æ ¹ï¼‰ä¸åˆ†éš”ç¬¦
                                try:
                                    repo_root = Path(__file__).resolve().parents[5]
                                    rel = space_ref.relative_to(repo_root)
                                    ext["op_space_ref"] = str(rel).replace("\\", "/")
                                except Exception:
                                    ext["op_space_ref"] = str(space_ref).replace("\\", "/")
                    except Exception:
                        pass
            except Exception as _e:
                # å¿½ç•¥è§„èŒƒå¼‚å¸¸ï¼Œç»§ç»­é€ä¼ åŸå§‹å­—æ®µ
                ext.setdefault("syntax_warnings", [])
                ext["syntax_warnings"].append(f"ops_detailed normalization error: {_e}")

            key = _seq_key(seq)
            prev = by_seq.get(key)
            if prev is None:
                by_seq[key] = {
                    "id": f"pkg_{ds_domain}_{abs(hash(key)) % (10**10)}",
                    "domain": ds_domain,
                    "sequence": seq,
                    "length": int(length),
                    "delta_risk": float(dr),
                    "cost": float(cost),
                    "score": float(score),
                    "created_at": ts_now,
                    "updated_at": ts_now,
                    "source": "debug_dataset",
                }
                # åˆå¹¶æ‰©å±•å­—æ®µ
                if ext:
                    by_seq[key].update(ext)
            else:
                # è‹¥é‡å¤ï¼Œåˆ™ä¿ç•™åˆ†æ•°æ›´é«˜çš„ä¸€æ¡ï¼Œå¹¶æ›´æ–°ç»Ÿè®¡æ—¶é—´
                try:
                    if float(score) > float(prev.get("score", -1e9)):
                        prev["delta_risk"] = float(dr)
                        prev["cost"] = float(cost)
                        prev["length"] = int(length)
                        prev["score"] = float(score)
                except Exception:
                    pass
                prev["updated_at"] = ts_now
                # åˆå¹¶/åˆ·æ–°æ‰©å±•å­—æ®µï¼ˆè‹¥æä¾›ï¼‰
                if ext:
                    prev.update(ext)
        except Exception:
            # å¿½ç•¥å¼‚å¸¸æ ·æœ¬ï¼Œç»§ç»­å¤„ç†
            continue

    # é‡æ–°æ•´ç†æ’åº
    items = list(by_seq.values())
    items.sort(key=lambda d: (
        -float(d.get("score", 0.0)),
        int(d.get("length", 0)),
        tuple(str(x) for x in d.get("sequence", []))
    ))

    # å†™ç›˜å‰çš„æœ€åè¡¥å…¨ï¼šä¸ºç¼ºå°‘å‚æ•°ç»†åŒ–ä¿¡æ¯çš„æ¡ç›®è¡¥é½é»˜è®¤ ops_detailedï¼ˆä¸è¦†ç›–å·²æœ‰ï¼‰
    try:
        from .op_space_utils import load_op_space, param_grid_of, params_from_grid  # type: ignore
        mod_dir2 = Path(__file__).resolve().parent
        space_ref2 = mod_dir2 / "operator_spaces" / f"{ds_domain}_op_space.v1.json"
        space2 = None
        if space_ref2.exists():
            space2 = load_op_space(str(space_ref2))
        if space2 is not None:
            for d in items:
                if d.get("ops_detailed"):
                    # æ ‡å‡†åŒ–å·²æœ‰çš„ op_space_ref ä¸ºç›¸å¯¹è·¯å¾„ï¼ˆå¦‚å¿…è¦ï¼‰
                    try:
                        if isinstance(d.get("op_space_ref"), str):
                            repo_root = Path(__file__).resolve().parents[5]
                            p = Path(d["op_space_ref"]).resolve()
                            relp = str(p.relative_to(repo_root)).replace("\\", "/")
                            d["op_space_ref"] = relp
                    except Exception:
                        pass
                    continue
                seq2 = list(d.get("sequence", []) or [])
                steps2 = []
                for nm in seq2:
                    try:
                        names2, grids2 = param_grid_of(space2, nm)
                    except Exception:
                        steps2.append({"name": nm})
                        continue
                    gi2 = []
                    for g in grids2:
                        L2 = len(g)
                        gi2.append(max(0, (L2 - 1) // 2))
                    prs2 = params_from_grid(space2, nm, gi2)
                    steps2.append({"name": nm, "grid_index": gi2, "params": prs2})
                if steps2:
                    d["ops_detailed"] = steps2
                    d.setdefault("op_space_id", space2.get("space_id", f"{ds_domain}.v1"))
                    try:
                        repo_root2 = Path(__file__).resolve().parents[5]
                        rel2 = space_ref2.relative_to(repo_root2)
                        d.setdefault("op_space_ref", str(rel2).replace("\\", "/"))
                    except Exception:
                        d.setdefault("op_space_ref", str(space_ref2).replace("\\", "/"))
    except Exception:
        pass

    text = json.dumps(items, ensure_ascii=False, indent=2)
    text = _normalize_lf(text)
    with out_path.open("w", encoding="utf-8", newline="\n") as f:
        f.write(text)
    return out_path


__all__ = [
    "ensure_store_dir",
    "ingest_from_debug_dataset",
]
