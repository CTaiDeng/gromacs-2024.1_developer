# SPDX-License-Identifier: GPL-3.0-only
# Copyright (C) 2025 GaoZheng
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, version 3 only.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
#
# --- è‘—ä½œæƒç‹¬ç«‹æ€§å£°æ˜ (Copyright Independence Declaration) ---
# æœ¬æ–‡ä»¶ï¼ˆâ€œè½½è·â€ï¼‰æ˜¯ä½œè€… (GaoZheng) çš„åŸåˆ›è‘—ä½œç‰©ï¼Œå…¶çŸ¥è¯†äº§æƒ
# ç‹¬ç«‹äºå…¶è¿è¡Œå¹³å° GROMACSï¼ˆâ€œå®¿ä¸»â€ï¼‰ã€‚
# æœ¬æ–‡ä»¶çš„æˆæƒéµå¾ªä¸Šè¿° SPDX æ ‡è¯†ï¼Œä¸å—â€œå®¿ä¸»â€è®¸å¯è¯çš„ç®¡è¾–ã€‚
# è¯¦æƒ…å‚è§é¡¹ç›®æ–‡æ¡£ "my_docs/project_docs/1762636780_ğŸš©ğŸš©gromacs-2024.1_developeré¡¹ç›®çš„è‘—ä½œæƒè®¾è®¡ç­–ç•¥ï¼šâ€œå®¿ä¸»-è½½è·â€ä¸â€œåŒè½¨åˆ¶â€å¤åˆæ¶æ„.md"ã€‚
# ------------------------------------------------------------------

from __future__ import annotations

import json
import os
import time as _t
from pathlib import Path
from typing import Any, Dict, List, Tuple


def _load_cfg(p: Path) -> Dict[str, Any]:
    return json.loads(p.read_text(encoding="utf-8"))


def _oneline(s: str, max_len: int = 240) -> str:
    try:
        t = s.replace("\r\n", "\n").replace("\r", "\n").replace("\t", " ").replace("\n", "\\n")
        return t[:max_len] + ("..." if len(t) > max_len else "")
    except Exception:
        return s


def _repo_root() -> Path:
    p = Path(__file__).resolve()
    for anc in [p.parent] + list(p.parents):
        try:
            if (anc / ".git").exists():
                return anc
        except Exception:
            continue
    try:
        return p.parents[6]
    except Exception:
        return p.parents[-1]


def _read_packages(p: Path) -> List[Dict[str, Any]]:
    try:
        return json.loads(p.read_text(encoding="utf-8"))
    except Exception:
        return []


def _domain_from_file(p: Path) -> str:
    return p.name.split("_")[0].lower()


def _ensure_repo_in_sys_path() -> None:
    try:
        import lbopb  # type: ignore  # noqa: F401
        return
    except Exception:
        pass
    try:
        import sys as _sys
        root = _repo_root()
        _sys.path.insert(0, str(root))
    except Exception:
        pass


def _ops_detailed_for(seq: List[str], domain: str) -> Tuple[List[Dict[str, Any]] | None, Dict[str, Any] | None]:
    try:
        from lbopb.src.rlsac.kernel.rlsac_pathfinder.op_space_utils import load_op_space, param_grid_of, params_from_grid  # type: ignore
        mod_dir = Path(__file__).resolve().parents[1]
        space_ref = mod_dir / "operator_spaces" / f"{domain}_op_space.v1.json"
        if not space_ref.exists():
            return None, None
        space = load_op_space(str(space_ref))
        steps: List[Dict[str, Any]] = []
        for nm in seq:
            try:
                names, grids = param_grid_of(space, nm)
            except Exception:
                steps.append({"name": nm})
                continue
            gi: List[int] = []
            for g in grids:
                L = len(g)
                gi.append(max(0, (L - 1) // 2))
            prs = params_from_grid(space, nm, gi)
            steps.append({"name": nm, "grid_index": gi, "params": prs})
        meta = {
            "op_space_id": space.get("space_id", f"{domain}.v1"),
            "op_space_ref": str(space_ref.relative_to(_repo_root())).replace("\\", "/"),
        }
        return steps, meta
    except Exception:
        return None, None


def verify_file(pack_file: Path, cfg: Dict[str, Any], *, out_dir: Path,
                debug: bool = True, prune: bool = True, limit: int | None = None) -> Dict[str, Any]:
    # ANSI color scheme (consistent with train.py)
    ANSI_RESET = "\x1b[0m"
    ANSI_RED = "\x1b[31;1m"
    ANSI_GREEN = "\x1b[32;1m"
    ANSI_YELLOW = "\x1b[33;1m"
    ANSI_CYAN = "\x1b[36;1m"
    ANSI_MAGENTA = "\x1b[35;1m"

    def _cprint(txt: str, color: str | None = None, always: bool = False) -> None:
        try:
            if color and (debug or always):
                print(f"{color}{txt}{ANSI_RESET}")
            else:
                print(txt)
        except Exception:
            print(txt)

    domain = _domain_from_file(pack_file)
    arr = _read_packages(pack_file)
    report_items: List[Dict[str, Any]] = []

    # LLM settings
    model_map = cfg.get("gemini_model_choose", {}) or {}
    gm = cfg.get("GEMINI_MODEL", None)
    if isinstance(gm, int):
        model = None
        for k, v in model_map.items():
            if int(v) == gm:
                model = str(k)
                break
    else:
        model = str(gm) if isinstance(gm, str) else None

    req_interval = float(cfg.get("llm_request_interval_sec", 0.0))
    last = 0.0
    # propagate LLM timeout and model to env (for HTTP client)
    try:
        _llm_to = cfg.get("llm_timeout_sec", None)
        if _llm_to is not None:
            os.environ["LBOPB_GEMINI_TIMEOUT_SEC"] = str(_llm_to)
        if isinstance(model, str) and model:
            os.environ["LBOPB_GEMINI_MODEL"] = model
            os.environ["GEMINI_MODEL"] = model
    except Exception:
        pass

    _ensure_repo_in_sys_path()
    from lbopb.src.rlsac.kernel.common.llm_oracle import build_pathfinder_prompt, call_llm  # type: ignore

    kept: List[Dict[str, Any]] = []
    total = len(arr)
    n_check = total if (limit is None or limit <= 0) else min(limit, total)
    _cprint(f"[æ ¡éªŒ] æ–‡ä»¶={pack_file} åŸŸ={domain} æ€»æ•°={total} æ£€æŸ¥={n_check} æ¨¡å‹={model or '<default>'} é—´éš”={req_interval}s", ANSI_CYAN, always=True)

    consecutive_unparsed = 0
    for idx, it in enumerate(arr[:n_check], start=1):
        seq = list(it.get("sequence", []) or [])
        _cprint(f"[æ ¡éªŒ:{idx}/{n_check}] å¼€å§‹ åºåˆ—={seq}", ANSI_YELLOW, always=True)

        # ä¸è¿›è¡Œ syntax_checkerï¼Œå›ºå®šè§†ä¸º Trueï¼ˆä»… LLM åˆ¤å®šï¼‰
        syn_ok = True

        # Prepare ops_detailed/meta
        ops_det = it.get("ops_detailed") if isinstance(it.get("ops_detailed"), list) else None
        if not ops_det:
            ops_det, extra = _ops_detailed_for(seq, domain)
        else:
            extra = {k: it.get(k) for k in ("op_space_id", "op_space_ref") if k in it}

        prompt = build_pathfinder_prompt(domain, seq, ops_det, extra)
        if debug:
            try:
                import json as _json
                _ops_prev = _oneline(_json.dumps(ops_det, ensure_ascii=False)) if ops_det else "<none>"
            except Exception:
                _ops_prev = "<err>"
            _cprint(f"[æ ¡éªŒ:{idx}/{n_check}] å‚æ•°={_ops_prev}", ANSI_YELLOW)
            _cprint(f"[æ ¡éªŒ:{idx}/{n_check}] æç¤ºè¯é¢„è§ˆ={_oneline(str(prompt))}", ANSI_CYAN)

        # throttle
        if req_interval > 0 and last > 0:
            w = (last + req_interval) - _t.time()
            if w > 0:
                _cprint(f"[æ ¡éªŒ:{idx}/{n_check}] é™æµ ç­‰å¾…={w:.2f}s", ANSI_CYAN)
                _t.sleep(w)

        # LLM è°ƒç”¨ï¼šå¤±è´¥/ä¸å¯è§£æé‡è¯• 3 æ¬¡ï¼›è¿ç»­å¤±è´¥ 3 æ¡åˆ™é€€å‡º
        max_attempts = 3
        attempt = 0
        llm_ok = False
        llm_raw: str | None = None
        t0 = _t.time()
        parsed = False
        while attempt < max_attempts:
            attempt += 1
            try:
                txt = call_llm(prompt, model=model)
            except Exception as e:
                txt = f"[Gemini Exception] {e}"
            llm_raw = str(txt) if txt is not None else None
            s = (llm_raw or "").strip()
            if s:
                if s == "1" or ("1" in s and "0" not in s):
                    llm_ok = True
                    parsed = True
                elif s == "0" or ("0" in s and "1" not in s):
                    llm_ok = False
                    parsed = True
            if parsed:
                break
            # æœªè§£ææˆ– HTTP é”™è¯¯ï¼šè¯»å– 429 çš„ retry æç¤ºæˆ–ä½¿ç”¨é…ç½®é—´éš”
            wait_sec = 0.0
            try:
                import re as _re
                m1 = _re.search(r"Please retry in\s*([0-9.]+)s", s)
                m2 = _re.search(r"\"retryDelay\"\s*:\s*\"([0-9.]+)s\"", s)
                if m1:
                    wait_sec = float(m1.group(1))
                elif m2:
                    wait_sec = float(m2.group(1))
            except Exception:
                wait_sec = 0.0
            if wait_sec <= 0.0:
                wait_sec = max(1.0, float(req_interval or 0.0))
            _cprint(f"[æ ¡éªŒ:{idx}/{n_check}] é‡è¯• æ¬¡æ•°={attempt}/{max_attempts} ç­‰å¾…={wait_sec:.2f}s", ANSI_CYAN)
            _t.sleep(wait_sec)
        last = _t.time()

        both_ok = bool(syn_ok and llm_ok)
        item_report = {
            "id": it.get("id"),
            "domain": domain,
            "sequence": seq,
            "syntax_ok": bool(syn_ok),
            "llm_ok": bool(llm_ok),
            "both_ok": bool(both_ok),
        }
        report_items.append(item_report)
        _resp_prev = _oneline(llm_raw or "<None>")
        if both_ok:
            _cprint(f"[æ ¡éªŒ:{idx}/{n_check}] ç»“æœ é€šè¿‡ (LLM=1)", ANSI_GREEN, always=True)
        else:
            _cprint(f"[æ ¡éªŒ:{idx}/{n_check}] ç»“æœ ä¸é€šè¿‡ (LLM=0 æˆ–æœªè§£æ)", ANSI_RED, always=True)
        if debug:
            _cprint(f"[æ ¡éªŒ:{idx}/{n_check}] LLMè°ƒç”¨ æ¨¡å‹={model or '<default>'} ç”¨æ—¶={(last-t0):.2f}s å“åº”é¢„è§ˆ={_resp_prev}", ANSI_MAGENTA)

        # è®°å½•â€œè¯·æ±‚å¤±è´¥/æœªè§£æâ€çš„è¿ç»­æ¬¡æ•°ï¼›è‹¥æœ¬æ¡å·²è§£æï¼ˆæ— è®º 1/0ï¼‰åˆ™æ¸…é›¶
        if not parsed:
            consecutive_unparsed += 1
        else:
            consecutive_unparsed = 0
        if consecutive_unparsed >= 3:
            raise SystemExit(f"[æ ¡éªŒ] ç»ˆæ­¢ï¼šè¿ç»­å¤±è´¥æ¡ç›®è¾¾åˆ° {consecutive_unparsed}")

        if both_ok or not prune:
            kept.append(it)

    # å†™å›ï¼ˆå‰ªé™¤å¤±è´¥é¡¹ï¼‰
    if prune:
        try:
            if n_check < total:
                kept.extend(arr[n_check:])
            with pack_file.open("w", encoding="utf-8", newline="\n") as f:
                f.write(json.dumps(kept, ensure_ascii=False, indent=2))
            if debug:
                _cprint(f"[æ ¡éªŒ] å·²å†™å›ï¼š{pack_file} ä¿ç•™={len(kept)}/{len(arr)} (å·²æ£€={n_check})", ANSI_CYAN)
        except Exception as e:
            print(f"[æ ¡éªŒ] å‰ªé™¤å†™å›å¤±è´¥: {e}")

    out = {
        "file": str(pack_file.relative_to(_repo_root())).replace("\\", "/"),
        "domain": domain,
        "count": len(arr),
        "checked": int(n_check),
        "ok_both": sum(1 for x in report_items if x["both_ok"]),
        "ok_syntax": sum(1 for x in report_items if x["syntax_ok"]),
        "ok_llm": sum(1 for x in report_items if x["llm_ok"]),
        "items": report_items,
    }
    with (out_dir / f"verify_{domain}.json").open("w", encoding="utf-8", newline="\n") as f:
        f.write(json.dumps(out, ensure_ascii=False, indent=2))
    return out


def main() -> None:
    base = Path(__file__).resolve().parent
    cfg_path = base.parent / "config.json"
    cfg = _load_cfg(cfg_path) if cfg_path.exists() else {}
    out_dir = base

    files = [
        base / "pem_operator_packages.json",
        base / "pdem_operator_packages.json",
        base / "pktm_operator_packages.json",
        base / "pgom_operator_packages.json",
        base / "tem_operator_packages.json",
        base / "prm_operator_packages.json",
        base / "iem_operator_packages.json",
    ]
    # é»˜è®¤ç­‰ä»·äº --debug --pruneï¼›å¯é™„åŠ æ•´æ•° N åªæ£€æŸ¥å‰ N æ¡
    import sys
    args = sys.argv[1:]
    debug = True
    prune = True
    limit: int | None = None
    for a in args:
        if a in ("--debug", "-d"):
            debug = True
        elif a in ("--prune", "-p"):
            prune = True
        elif not a.startswith('-'):
            try:
                limit = int(a)
            except Exception:
                continue

    # æ¯æ¬¡è¿è¡Œå…ˆæ¸…ç©º PEM ä¸“ç”¨è¾“å‡ºæ–‡ä»¶ï¼Œç¡®ä¿åªå­˜æœ¬æ¬¡
    pem_out = base / "verify_pem.json"
    try:
        with pem_out.open("w", encoding="utf-8", newline="\n") as f:
            f.write("{}")
    except Exception:
        pass

    summary: Dict[str, Any] = {"reports": []}
    for f in files:
        if not f.exists():
            continue
        rep = verify_file(f, cfg, out_dir=out_dir, debug=debug, prune=prune, limit=limit)
        summary["reports"].append(rep)
        # è‹¥ä¸º PEM åŸŸï¼Œå•ç‹¬å†™å…¥ verify_pem.jsonï¼ˆä»…ä¿å­˜æœ¬æ¬¡ï¼‰
        try:
            if str(rep.get("domain","")) == "pem":
                with pem_out.open("w", encoding="utf-8", newline="\n") as f:
                    f.write(json.dumps(rep, ensure_ascii=False, indent=2))
        except Exception:
            pass
    with (out_dir / "verify_summary.json").open("w", encoding="utf-8", newline="\n") as f:
        f.write(json.dumps(summary, ensure_ascii=False, indent=2))
    print(json.dumps({
        "ok_both_total": sum(r["ok_both"] for r in summary["reports"]),
        "count_total": sum(r["count"] for r in summary["reports"]),
        "checked_total": sum(r.get("checked", r.get("count", 0)) for r in summary["reports"]),
    }, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()
