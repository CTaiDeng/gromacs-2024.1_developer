#!/usr/bin/env python3

# SPDX-License-Identifier: GPL-3.0-only
# Copyright (C) 2025 GaoZheng
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, version 3 only.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
#
# --- è‘—ä½œæƒç‹¬ç«‹æ€§å£°æ˜ (Copyright Independence Declaration) ---
# æœ¬æ–‡ä»¶ï¼ˆâ€œè½½è·â€ï¼‰æ˜¯ä½œè€… (GaoZheng) çš„åŸåˆ›è‘—ä½œç‰©ï¼Œå…¶çŸ¥è¯†äº§æƒ
# ç‹¬ç«‹äºå…¶è¿è¡Œå¹³å° GROMACSï¼ˆâ€œå®¿ä¸»â€ï¼‰ã€‚
# æœ¬æ–‡ä»¶çš„æˆæƒéµå¾ªä¸Šè¿° SPDX æ ‡è¯†ï¼Œä¸å—â€œå®¿ä¸»â€è®¸å¯è¯çš„ç®¡è¾–ã€‚
# è¯¦æƒ…å‚è§é¡¹ç›®æ–‡æ¡£ "my_docs/project_docs/1762636780_ğŸš©ğŸš©gromacs-2024.1_developeré¡¹ç›®çš„è‘—ä½œæƒè®¾è®¡ç­–ç•¥ï¼šâ€œå®¿ä¸»-è½½è·â€ä¸â€œåŒè½¨åˆ¶â€å¤åˆæ¶æ„.md"ã€‚
# ------------------------------------------------------------------

from __future__ import annotations

import json
import time
from pathlib import Path
from typing import Dict, List, Any, Tuple
import hashlib

MODULES: List[str] = ["pem", "pdem", "pktm", "pgom", "tem", "prm", "iem"]


def _repo_root() -> Path:
    p = Path(__file__).resolve()
    for anc in [p.parent] + list(p.parents):
        try:
            if (anc / ".git").exists():
                return anc
        except Exception:
            continue
    return p.parents[-1]


def _ensure_repo_in_sys_path() -> None:
    try:
        import lbopb  # type: ignore
        return
    except Exception:
        pass
    try:
        import sys as _sys
        root = _repo_root()
        if str(root) not in _sys.path:
            _sys.path.insert(0, str(root))
    except Exception:
        pass


def _read_json(p: Path) -> Any:
    try:
        return json.loads(p.read_text(encoding="utf-8"))
    except Exception:
        return None


def _write_json(p: Path, data: Any) -> None:
    txt = json.dumps(data, ensure_ascii=False, indent=2).replace("\r\n", "\n")
    p.parent.mkdir(parents=True, exist_ok=True)
    with open(p, "w", encoding="utf-8", newline="\n") as f:
        f.write(txt)


def _color(txt: str, code: int) -> str:
    # ANSI color helper: 31=red, 32=green, 33=yellow, 36=cyan
    try:
        return f"\033[{code}m{txt}\033[0m"
    except Exception:
        return txt


def collect_pairwise_entries(mono_dir: Path) -> Dict[Tuple[str, str], List[Dict[str, Any]]]:
    _ensure_repo_in_sys_path()
    out: Dict[Tuple[str, str], List[Dict[str, Any]]] = {}
    for i, a in enumerate(MODULES):
        for b in MODULES[i + 1:]:
            fp = mono_dir / f"{a}_{b}_operator_packages.json"
            if not fp.exists():
                fp2 = mono_dir / f"{b}_{a}_operator_packages.json"
                if fp2.exists():
                    fp = fp2
                else:
                    continue
            arr = _read_json(fp)
            if not isinstance(arr, list):
                continue
            norm: List[Dict[str, Any]] = []
            # å»¶è¿Ÿå¯¼å…¥å‚æ•°ç©ºé—´å·¥å…·ï¼ˆå­˜åœ¨åˆ™ç”Ÿæˆå¸¦å‚æ•°çš„ ops_detailedï¼‰
            try:
                from lbopb.src.rlsac.kernel.rlsac_pathfinder.make_samples_with_params import synth_ops  # type: ignore
                base_root = Path(__file__).resolve().parents[2] / 'rlsac_pathfinder'
            except Exception:
                synth_ops = None  # type: ignore
                base_root = None  # type: ignore

            def build_steps(domain: str, seq: List[str]) -> List[Dict[str, Any]]:
                if synth_ops is None or base_root is None:
                    return [{"name": nm, "grid_index": [], "params": {}} for nm in seq]
                try:
                    steps = list(synth_ops(domain, seq, base_root))
                    # å…œåº•è¡¥é½ç»“æ„
                    for st in steps:
                        if "params" not in st:
                            st["params"] = {}
                        if "grid_index" not in st:
                            st["grid_index"] = []
                    return steps
                except Exception:
                    return [{"name": nm, "grid_index": [], "params": {}} for nm in seq]
            for it in arr:
                seqs = it.get("sequences") or {}
                pa = list(seqs.get(a) or [])
                pb = list(seqs.get(b) or [])
                entry: Dict[str, Any] = {
                    "id": str(it.get("id", "")),
                    "pair": {"a": a, "b": b},
                    "sequences": {a: pa, b: pb},
                    "created_at": int(it.get("created_at", time.time())),
                    "updated_at": int(it.get("updated_at", time.time())),
                    "source": str(it.get("source", "pair_generated")),
                    "validation": it.get("validation", {}),
                }
                # ç”Ÿæˆ ops_detailedï¼ˆåŒ…å«å‚æ•°å–å€¼ï¼‰
                entry["ops_detailed"] = {a: build_steps(a, pa), b: build_steps(b, pb)}
                norm.append(entry)
            out[(a, b)] = norm
    return out


def build_global_lexicon_from_pairs(pairs: Dict[Tuple[str, str], List[Dict[str, Any]]], *, max_items: int = 100) -> List[Dict[str, Any]]:
    """åœ¨ä¸¤ä¸¤è”ç»œçº¦æŸä¸‹ï¼Œæœç´¢â€œå®Œå¤‡ä¸ƒåŸŸè”ç»œâ€çš„ä¸€è‡´ä¸ƒåŸŸç®—å­åŒ…ï¼ˆæ¯åŸŸä¸€æ¡åºåˆ—ï¼‰ã€‚

    - ä»…å½“æ‰¾åˆ°æ»¡è¶³æ‰€æœ‰ 21 å¯¹çº¦æŸçš„ä¸ƒåŸŸç»„åˆæ—¶æ‰äº§å‡ºï¼ˆæ¯æ­¥å«å‚æ•°/å–å€¼ï¼‰ã€‚
    - è‹¥æ— è§£ï¼Œè¿”å›ç©ºåˆ—è¡¨ã€‚
    """
    _ensure_repo_in_sys_path()

    # 1) æ„å»ºæ¯ä¸ª pair çš„â€œå…è®¸ç»„åˆâ€é›†åˆï¼Œä»¥åŠæ¯ä¸ªåŸŸçš„å€™é€‰åºåˆ—æ± 
    def key_of(seq: List[str]) -> Tuple[str, ...]:
        return tuple(str(x) for x in (seq or []))

    domain_index: Dict[str, int] = {m: i for i, m in enumerate(MODULES)}
    allowed: Dict[Tuple[str, str], set[Tuple[Tuple[str, ...], Tuple[str, ...]]]] = {}
    domain_pool: Dict[str, set[Tuple[str, ...]]] = {m: set() for m in MODULES}

    for (a, b), arr in pairs.items():
        a2, b2 = (a, b) if domain_index[a] < domain_index[b] else (b, a)
        st: set = allowed.setdefault((a2, b2), set())
        for it in arr:
            seqs = it.get("sequences") or {}
            sa = key_of(seqs.get(a2) or [])
            sb = key_of(seqs.get(b2) or [])
            st.add((sa, sb))
            if sa:
                domain_pool[a2].add(sa)
            if sb:
                domain_pool[b2].add(sb)

    # è¦†ç›–æ£€æŸ¥ï¼šæ¯ä¸ªåŸŸå¿…é¡»è‡³å°‘æœ‰ä¸€ä¸ªå€™é€‰åºåˆ—
    if not all(domain_pool[m] for m in MODULES):
        return []

    # 2) å›æº¯æœç´¢ä¸€è‡´èµ‹å€¼ï¼ˆæ»¡è¶³æ‰€æœ‰ pair çº¦æŸï¼‰
    solutions: List[Dict[str, List[str]]] = []
    order = sorted(MODULES, key=lambda m: len(domain_pool[m]))  # å…ˆæœå€™é€‰å°‘çš„åŸŸ

    def consistent(assign: Dict[str, Tuple[str, ...]], m: str, val: Tuple[str, ...]) -> bool:
        mi = domain_index[m]
        for n, v in assign.items():
            a, b = (m, n) if domain_index[m] < domain_index[n] else (n, m)
            va, vb = (val, v) if a == m else (v, val)
            if (a, b) not in allowed:
                return False
            if (va, vb) not in allowed[(a, b)]:
                return False
        return True

    def backtrack(i: int, assign: Dict[str, Tuple[str, ...]]):
        if len(solutions) >= max_items:
            return
        if i == len(order):
            solutions.append({k: list(map(str, v)) for k, v in assign.items()})
            return
        m = order[i]
        for val in domain_pool[m]:
            if consistent(assign, m, val):
                assign[m] = val
                backtrack(i + 1, assign)
                assign.pop(m, None)

    backtrack(0, {})

    if not solutions:
        return []

    # 3) æ„é€ å«å‚æ•°ä¸å–å€¼çš„è¾“å‡ºæ¡ç›®
    items: List[Dict[str, Any]] = []
    try:
        from lbopb.src.rlsac.kernel.rlsac_pathfinder.make_samples_with_params import synth_ops  # type: ignore
        base_root = Path(__file__).resolve().parents[2] / 'rlsac_pathfinder'
        def build_steps(domain: str, seq: List[str]) -> List[Dict[str, Any]]:
            try:
                steps = list(synth_ops(domain, seq, base_root))
                for st in steps:
                    if "params" not in st:
                        st["params"] = {}
                    if "grid_index" not in st:
                        st["grid_index"] = []
                return steps
            except Exception:
                return [{"name": nm, "grid_index": [], "params": {}} for nm in seq]
    except Exception:
        def build_steps(domain: str, seq: List[str]) -> List[Dict[str, Any]]:  # type: ignore
            return [{"name": nm, "grid_index": [], "params": {}} for nm in seq]

    for sol in solutions[:max_items]:
        chosen = {m: list(sol[m]) for m in MODULES}
        ops = {m: build_steps(m, list(sol[m])) for m in MODULES}
        # ä»¥ chosen+ops_detailed çš„è§„èŒƒ JSON ä½œä¸ºå“ˆå¸Œè¾“å…¥
        blob = json.dumps({"chosen": chosen, "ops_detailed": ops}, ensure_ascii=False, sort_keys=True, separators=(",", ":")).encode("utf-8")
        hid = hashlib.sha256(blob).hexdigest()
        item: Dict[str, Any] = {
            "id": f"global_{hid}",
            "chosen": chosen,
            "ops_detailed": ops,
            "meta": {"strategy": "pairwise_complete_clique"},
            "score": 0.0,
        }
        items.append(item)
    return items


def main() -> None:
    import sys
    mod_dir = Path(__file__).resolve().parents[1]
    mono_dir = mod_dir / "monoid_packages"
    out_dir = mod_dir / "law_lexicon"
    out_dir.mkdir(parents=True, exist_ok=True)

    # 1) åŠ è½½ pairs çº§æ•°æ®ï¼ˆä¸è½ç›˜ pairwise æ–‡ä»¶ï¼‰
    pairs = collect_pairwise_entries(mono_dir)

    # è¦†ç›–æ€§æ£€æŸ¥ï¼šå¿…é¡»å…·å¤‡â€œå®Œå¤‡ä¸ƒåŸŸè”ç»œâ€ï¼Œå¦åˆ™æ”¾å¼ƒå¹¶å½©è‰²æ‰“å°ç»“æœ
    pool: Dict[str, List[List[str]]] = {m: [] for m in MODULES}
    for (a, b), arr in pairs.items():
        for it in arr:
            seqs = it.get("sequences") or {}
            sa = list(seqs.get(a) or [])
            sb = list(seqs.get(b) or [])
            if sa:
                pool[a].append(sa)
            if sb:
                pool[b].append(sb)
    missing = [m for m in MODULES if not pool[m]]
    if missing:
        print(_color("[global-lexicon] è¦†ç›–æ€§ä¸è¶³ï¼šç¼ºå°‘å®Œå¤‡ä¸ƒåŸŸè”ç»œï¼›æ”¾å¼ƒå†™å…¥ global_law_connections.jsonã€‚", 31))
        print(_color("åŸŸè¦†ç›–ç»Ÿè®¡ï¼š", 36))
        for m in MODULES:
            cnt = len(pool[m])
            col = 32 if cnt > 0 else 31
            print(_color(f" - {m}: {cnt}", col))
        # æ¸…ç†æ®‹ç•™çš„ pairwise lexicon æ–‡ä»¶ï¼Œç¡®ä¿ç›®å½•æ•´æ´
        for p in out_dir.glob("lexicon_*.json"):
            try:
                p.unlink()
            except Exception:
                pass
        return

    # 2) æœç´¢å®Œå¤‡ä¸ƒåŸŸè”ç»œå¹¶å†™å…¥ï¼ˆæ¯æ¬¡é‡å†™ï¼‰
    global_items = build_global_lexicon_from_pairs(pairs, max_items=50)
    # å§‹ç»ˆé‡å†™ï¼Œè‹¥æ— è§£å†™å…¥ç©ºæ•°ç»„
    _write_json(out_dir / "global_law_connections.json", global_items)
    # è‹¥å†å²å­˜åœ¨ global_lexicon.jsonï¼Œåˆ™æ¸…ç†
    old = out_dir / "global_lexicon.json"
    try:
        if old.exists():
            old.unlink()
    except Exception:
        pass

    # å§‹ç»ˆæ¸…ç†æ®‹ç•™çš„ pairwise lexicon æ–‡ä»¶ï¼Œç¡®ä¿åªä¿ç•™å…¨å±€æ–‡ä»¶
    for p in out_dir.glob("lexicon_*.json"):
        try:
            p.unlink()
        except Exception:
            pass
    print(f"[lexicon] pairwise=0 files (skipped), global={len(global_items)} entries written under {out_dir}")


if __name__ == "__main__":
    main()
