# SPDX-License-Identifier: GPL-3.0-only
# Copyright (C) 2025 GaoZheng
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, version 3 only.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
#
# --- è‘—ä½œæƒç‹¬ç«‹æ€§å£°æ˜Ž (Copyright Independence Declaration) ---
# æœ¬æ–‡ä»¶ï¼ˆâ€œè½½è·â€ï¼‰æ˜¯ä½œè€… (GaoZheng) çš„åŽŸåˆ›è‘—ä½œç‰©ï¼Œå…¶çŸ¥è¯†äº§æƒ
# ç‹¬ç«‹äºŽå…¶è¿è¡Œå¹³å° GROMACSï¼ˆâ€œå®¿ä¸»â€ï¼‰ã€‚
# æœ¬æ–‡ä»¶çš„æŽˆæƒéµå¾ªä¸Šè¿° SPDX æ ‡è¯†ï¼Œä¸å—â€œå®¿ä¸»â€è®¸å¯è¯çš„ç®¡è¾–ã€‚
# è¯¦æƒ…å‚è§é¡¹ç›®æ–‡æ¡£ "my_docs/project_docs/1762636780_ðŸš©ðŸš©gromacs-2024.1_developeré¡¹ç›®çš„è‘—ä½œæƒè®¾è®¡ç­–ç•¥ï¼šâ€œå®¿ä¸»-è½½è·â€ä¸Žâ€œåŒè½¨åˆ¶â€å¤åˆæž¶æž„.md"ã€‚
# ------------------------------------------------------------------

from __future__ import annotations

import json
from pathlib import Path
import torch


def soft_update(target: torch.nn.Module, source: torch.nn.Module, tau: float) -> None:
    with torch.no_grad():
        for tp, sp in zip(target.parameters(), source.parameters()):
            tp.data.mul_(1.0 - tau).add_(sp.data, alpha=tau)


def select_device_from_config(cfg_path: Path) -> torch.device:
    """è§£æžè®¾å¤‡é€‰æ‹©ï¼Œå…¼å®¹æ—§å­—æ®µï¼š
    - æ—§ï¼š`use_gpu`(bool) + `device`(str: "cpu"/"cuda:0")
    - æ–°ï¼š`device_choose`(dict: name->id) + `device`(int id)
            æˆ– `device`(str: name)
    è¿”å›žå¯ç”¨çš„ `torch.device`ï¼›è‹¥è¯·æ±‚ GPU ä½†ä¸å¯ç”¨ï¼Œåˆ™å›žé€€ CPUã€‚
    """
    cfg = json.loads(Path(cfg_path).read_text(encoding="utf-8"))

    # 1) æ–°é£Žæ ¼è§£æžï¼šdevice å¯ä¸º str åç§°æˆ– int ç¼–å·
    dev_mapping = cfg.get("device_choose", {}) or {}
    dev = cfg.get("device", None)
    name: str | None = None
    if isinstance(dev, str):
        name = dev.strip().lower()
    elif isinstance(dev, int) and isinstance(dev_mapping, dict) and dev_mapping:
        for k, v in dev_mapping.items():
            try:
                if int(v) == dev:
                    name = str(k).strip().lower()
                    break
            except Exception:
                continue

    # 2) æ—§é£Žæ ¼å›žé€€
    if name is None:
        use_gpu = bool(cfg.get("use_gpu", False))
        requested_device = str(cfg.get("device", "cpu")).strip().lower()
        if use_gpu:
            name = "gpu"
        else:
            # è‹¥æ—§å­—æ®µç›´æŽ¥ç»™äº† cuda:*ï¼Œä¹ŸæŒ‰ gpu å¤„ç†
            name = "gpu" if requested_device.startswith("cuda") else "cpu"

    # 3) æ˜ å°„åˆ° torch.device
    if name == "gpu":
        if torch.cuda.is_available():
            # å…è®¸æœªæ¥æ‰©å±•ï¼šå¦‚æžœé…ç½®æä¾› cuda:* åˆ™ç›´æŽ¥ä½¿ç”¨
            requested = str(cfg.get("device", "")).strip().lower()
            return torch.device(requested if requested.startswith("cuda") else "cuda:0")
        return torch.device("cpu")
    # é»˜è®¤ CPU
    return torch.device("cpu")


def discrete_entropy(probs: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:
    p = torch.clamp(probs, eps, 1.0)
    return -(p * torch.log(p)).sum(dim=-1)
