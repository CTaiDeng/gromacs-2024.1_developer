# 训练样本（JSON 示例）

- 本目录提供 JSON 形式的训练样本示例，便于理解 `(state, action, reward, next_state, done)` 的结构。
- rlsac_hiv 实际训练数据由与环境交互在线产生；此处样本用于演示或离线预热。

## 文件与格式

- `samples.demo.json`：数组，每个元素是一条样本：
    - `state`: 浮点数组（长度 = 7 + 5*7 + M + 1 = 60；M=17 为全局干预算子数）。
    - `action`: 整型动作 id（参考同目录 `../op_index.json`）。
    - `reward`: 浮点奖励。
    - `next_state`: 同 `state` 维度。
    - `done`: 回合终止标记（布尔）。

说明：示例中 `state/next_state` 以 0/1 占位，真实训练由环境生成更丰富的数值特征。

## 样本序列示例与解释

示例（与 `samples.demo.json` 中第一条一致）：

```
{
  "state": [
    1,0,0,0,0,0,0,
    0,0,0,0,0, 0,0,0,0,0, 0,0,0,0,0,
    0,0,0,0,0, 0,0,0,0,0, 0,0,0,
    1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    0
  ],
  "action": 0,
  "reward": 0.8,
  "next_state": [
    1,0,0,0,0,0,0,
    0,0,0,0,0, 0,0,0,0,0, 0,0,0,0,0,
    0,0,0,0,0, 0,0,0,0,0, 0,0,0,
    0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    0.5
  ],
  "done": false
}
```

解释（字段与向量含义）：

- `state`
    - 前 7 位为 `module_onehot(7)`：`1,0,0,0,0,0,0` 表示当前推进模块为 `pem`。
    - 后接每模块的数值特征（`B,P,F,N,risk`）共 `5*7` 位：示例中均为 `0`（占位）。
    - 再接 `next_op_onehot(M)`（此处 M=17，对应全局干预算子数）：`1,0,0,...` 表示“下一应选算子”的 id 为 `0`（见
      `../op_index.json`，通常对应 `Inflammation`）。
    - 最后 1 位为 `pos`：`0` 表示在该模块目标序列的起始位置。
- `action`: `0`，智能体本步选择了 id 为 `0` 的干预算子（与 `op_index.json` 中的映射一致）。
- `reward`: `0.8`，示例值，代表基于 `Δrisk − λ·cost` 的即时奖励（正值表示风险下降收益大于代价惩罚）。
- `next_state`
    - 同维度向量。`next_op_onehot` 由 `1,0,0,...` 变为 `0,1,0,...`，表示下一应选算子从 id=0 切换为 id=1（例如从
      `Inflammation` 切换到 `Apoptosis`）。
    - `pos` 变为 `0.5`，示意推进到序列中段（示例占位）。
- `done`: `false`，表示回合尚未终止（该模块序列尚未全部完成）。

提示：

- 若你需要将 `action` 反查成具体干预算子名，可用 `../op_index.json` 中的 `id2op[action]`。
- 真实训练时，`state/next_state` 的数值由环境基于模块状态与算子应用动态生成，非固定 0/1。



